# 第三版声纹识别接口

## 对应文件：voiceprint_recognition_test_api.py

### 主要变化：删除所有与数据库的相关操作，声纹注册器直接返回该段录音的特征数组，不在做本地保存文件处理。

### 主要函数接口：

### 数据集声纹标注器：

```python
def database_to_viocefeature(file_path)
```

输入数据集文件的地址

![image-20210124192258003](D:\graduation_project\Kersa-Speaker-Recognition-master\第三版声纹识别接口.assets\image-20210124192258003.png)

调用示例：

```
database_to_viocefeature("D:\graduation_project\声纹识别视频\声纹数据集")
```

该函数将自动识别数据集中以人名为命名的文件夹，并拼接人名文件夹里所有的MP3进行特征提取，返回json格式的结果，key值为人名，key在字典中所对应的值为特征数组

### 普通版本的声纹标注器：

```python
def vedio_to_viocefeature(file_path,start_time,stop_time,voice_name,flag):
```

输入：视频地址，视频中的起始时间，结束时间，人物名字，以及flag

解释flag：flag=1时，函数将无视start_time,stop_time的值，直接对整个视频进行声纹提取，
flag=0时，start_time,stop_time将起作用，根据start_time,stop_time进行声纹提取

### start_time,stop_time格式：

00:00:00（小时：分钟：秒）或者00:00（分钟：秒）

## 声纹识别部分

### 根据srt对视频进行声纹识别

```python
def recognition_video_2(voiceprint_dict,video_path,srt_path):
```

输入：

voiceprint_dict：声纹字典，是目前数据库中所有的声纹特征

例：{"tlp":[特征数组]}

video_path：视频地址

srt_path：字幕srt文件地址

输出：示例：{'unknown': [], '迪-L-梅伯恩': [[0, 63],[87,95]]}  识别出0-63秒和87-95秒中讲话人为迪-L-梅伯恩

返回的是json格式的数据



